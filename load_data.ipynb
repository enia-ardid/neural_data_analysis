import os
import numpy as np
import pandas as pd

# ===> Parameters (edit as needed)
data_folder = os.path.expanduser("~/Desktop/")  # Set full path to your data folder
rat = "jc320"
day = "240924"
sessions = ["training1", "training2"]  # Use only one if needed

base_path = os.path.join(data_folder, f"{rat}-{day}")

# ----------- Helper: Load and concat files -----------
def load_and_concat(filenames, axis=0):
    arrays = [np.loadtxt(f) for f in filenames]
    return np.concatenate(arrays, axis=axis)

def load_des_with_noise(des_path):
    des = pd.read_csv(des_path, header=None, names=["type"])
    noise_df = pd.DataFrame({"type": ["noise", "multiunit"]})
    des_full = pd.concat([noise_df, des], ignore_index=True)
    return des_full

def load_txt_list(path_list):
    return [list(map(int, open(p).read().split())) for p in path_list]

# ----------- Initialize containers -----------
res_all = []
clu_all = []
whl_all = []
whl_speed_all = []
reward_arms_all = []
all_arms_all = []
trials_all = []

lwhl_raw_all = []
lwhl_all = []
lwhl_speed_all = []

# ----------- Gather all paths (no lectura a√∫n) -----------
for session in sessions:
    print(f"üîÑ Loading session: {session}")

    # .res and .clu
    res_path = os.path.join(base_path, f"{rat}-{day}_{session}.res")
    clu_path = os.path.join(base_path, f"{rat}-{day}_{session}.clu")
    res = np.loadtxt(res_path, dtype=int)
    clu = np.loadtxt(clu_path, dtype=int)[1:]  # skip first element
    res_all.append(res)
    clu_all.append(clu)

    # File paths only (headers will be preserved later if needed)
    whl_all.append(os.path.join(base_path, f"{rat}-{day}_{session}.whl"))
    whl_speed_all.append(os.path.join(base_path, f"{rat}_{day}_{session}.speed"))
    trials_all.append(os.path.join(base_path, f"{rat}_{day}_{session}.trials"))
    lwhl_raw_all.append(os.path.join(base_path, f"{rat}_{day}_{session}.lwhl_raw"))
    lwhl_all.append(os.path.join(base_path, f"{rat}_{day}_{session}.lwhl"))
    lwhl_speed_all.append(os.path.join(base_path, f"{rat}_{day}_{session}.lwhl_speed"))
    reward_arms_all.append(os.path.join(base_path, f"{rat}-{day}_{session}.reward_arms"))
    all_arms_all.append(os.path.join(base_path, f"{rat}-{day}_{session}.all_arms"))

# ----------- Concatenate .res and .clu -----------
res = np.concatenate(res_all)
clu = np.concatenate(clu_all)
print(f"‚úÖ res length: {len(res)}")
print(f"‚úÖ clu length: {len(clu)} (should match res)")

# ----------- Load .des with noise/multiunit types prepended -----------
des_path = os.path.join(base_path, f"{rat}-{day}.des")
putative_type = load_des_with_noise(des_path)
print(f"‚úÖ des loaded: {len(putative_type)} total cluster types")

# ----------- Load and concat .whl (no header) -----------
whl_list = [pd.read_csv(f, sep="\s+", header=None) for f in whl_all]
whl = pd.concat(whl_list, ignore_index=True)
print(f"‚úÖ whl shape: {whl.shape}")

# ----------- Load and concat .speed robustly (no header) -----------
speed_all = []
for speed_path in whl_speed_all:
    try:
        speed_df = pd.read_csv(speed_path, sep=None, engine="python", header=None)
        speed_col = speed_df.select_dtypes(include=[np.number]).iloc[:, 0]
        speed_all.append(speed_col.values)
    except Exception as e:
        print(f"‚ö†Ô∏è Error loading {speed_path}: {e}")

speed = np.concatenate(speed_all)
print(f"‚úÖ speed length: {len(speed)}")
print(f"‚ö†Ô∏è NaNs in speed: {np.isnan(speed).sum()} / {len(speed)}")

# ----------- Load reward_arms and all_arms -----------
reward_arms = load_txt_list(reward_arms_all)
print(f"‚úÖ Loaded {len(reward_arms)} reward_arms files")

all_arms = []
for file_path in all_arms_all:
    with open(file_path, "r") as f:
        for line in f:
            if line.strip():
                arms = [int(x) for x in line.strip().split()]
                all_arms.append(arms)

print(f"‚úÖ Loaded {len(all_arms)} trials from all_arms files")
print("üéØ Example trial arms:", all_arms[0])

# ----------- Load and parse .trials (no header) -----------
trials_segments = []
for tpath in trials_all:
    with open(tpath, "r") as f:
        for line in f:
            line = line.strip()
            if line:
                times = [int(x) for x in line.split()]
                trials_segments.append(times)

print(f"‚úÖ Loaded {len(trials_segments)} trial segments from .trials")
print("‚è±Ô∏è  Example trial timestamps:", trials_segments[0])

# ----------- Load .lwhl_raw, .lwhl and .lwhl_speed (WITH header) -----------
lwhl_raw_list   = [pd.read_csv(f, sep="\s+", header=0) for f in lwhl_raw_all]
lwhl_list       = [pd.read_csv(f, sep="\s+", header=0) for f in lwhl_all]
lwhl_speed_list = [pd.read_csv(f, sep="\s+", header=0) for f in lwhl_speed_all]

lwhl_raw   = pd.concat(lwhl_raw_list, ignore_index=True)
lwhl       = pd.concat(lwhl_list, ignore_index=True)
lwhl_speed = pd.concat(lwhl_speed_list, ignore_index=True)

print(f"‚úÖ lwhl_raw shape: {lwhl_raw.shape}")
print(f"‚úÖ lwhl shape: {lwhl.shape}")
print(f"‚úÖ lwhl_speed shape: {lwhl_speed.shape}")
